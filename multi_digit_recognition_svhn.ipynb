{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-digit-recognition-svhn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harmandubb/Datacenter/blob/master/multi_digit_recognition_svhn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "4YVxz2kUXowA",
        "outputId": "23507601-447e-4531-b44b-0afdea1870d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_QUuHcyyF5iq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "93fc47fd-d045-49e4-98ba-922edf4f2306"
      },
      "cell_type": "code",
      "source": [
        "# Module Imports\n",
        "from __future__ import print_function\n",
        "import random\n",
        "from os import listdir\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import np_utils\n",
        "\n",
        "from six.moves import cPickle as pickle\n",
        "from six.moves import range\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'np_utils' from 'keras.utils' (/usr/local/lib/python3.11/dist-packages/keras/api/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0dc2b61621ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'np_utils' from 'keras.utils' (/usr/local/lib/python3.11/dist-packages/keras/api/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I1dsidLuUQ-l"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi Digit Number Recognition with SVHN\n",
        "\n",
        "This notebook implements multi digit number recognition using SVHN dataset that will be used to recognize house numbers at the streets. It can be considered as second version of the previous multi digit recognition which uses MNIST database. Keras and Tensorflow libraries are used to build the recognizer.\n",
        "This recognizer extracts digit from the image using Convolutional Neural Network Classifier."
      ]
    },
    {
      "metadata": {
        "id": "F_giURzYGjWO"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Setting the random seed so that the results are reproducible.\n",
        "random.seed(42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifZinCXN3yk1"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "pKZMq9lA3x2P"
      },
      "cell_type": "code",
      "source": [
        "pickle_file = 'SVHN_multi_crop.pickle'\n",
        "\n",
        "with open(pickle_file, 'rb') as f:\n",
        "    save = pickle.load(f)\n",
        "    train_dataset = save['train_dataset']\n",
        "    train_labels = save['train_labels']\n",
        "    valid_dataset = save['valid_dataset']\n",
        "    valid_labels = save['valid_labels']\n",
        "    test_dataset = save['test_dataset']\n",
        "    test_labels = save['test_labels']\n",
        "    del save  # hint to help gc free up memory\n",
        "    print('Training set', train_dataset.shape, train_labels.shape)\n",
        "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "    print('Test set', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UK68ofOrHnI1"
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_dataset[50], cmap='gray')\n",
        "\n",
        "print(\"Label for image: {}\".format(train_labels[50]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xOQpSYQNHKIu"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert Labels\n",
        "This function converts each digit label to one-hot array."
      ]
    },
    {
      "metadata": {
        "id": "slWvJtn2Kts1"
      },
      "cell_type": "code",
      "source": [
        "# Converting labels to One-hot representations of shape (set_size, digits, classes)\n",
        "possible_classes = 11\n",
        "\n",
        "def convert_labels(labels):\n",
        "\n",
        "    # As per Keras conventions, the multiple labels need to be of the form [array_digit1,...5]\n",
        "    # Each digit array will be of shape (60000,11)\n",
        "\n",
        "    # Declare output ndarrays\n",
        "    # 5 for digits, 11 for possible classes\n",
        "    dig0_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig1_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig2_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig3_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig4_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "\n",
        "    for index,label in enumerate(labels):\n",
        "\n",
        "        # Using np_utils from keras to OHE the labels in the image\n",
        "        dig0_arr[index,:] = np_utils.to_categorical(label[0],possible_classes)\n",
        "        dig1_arr[index,:] = np_utils.to_categorical(label[1],possible_classes)\n",
        "        dig2_arr[index,:] = np_utils.to_categorical(label[2],possible_classes)\n",
        "        dig3_arr[index,:] = np_utils.to_categorical(label[3],possible_classes)\n",
        "        dig4_arr[index,:] = np_utils.to_categorical(label[4],possible_classes)\n",
        "\n",
        "    return [dig0_arr,dig1_arr,dig2_arr,dig3_arr,dig4_arr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17m-itv9Lizo"
      },
      "cell_type": "code",
      "source": [
        "train_labels = convert_labels(train_labels)\n",
        "test_labels = convert_labels(test_labels)\n",
        "valid_labels = convert_labels(valid_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NOjPwpQTLmAn"
      },
      "cell_type": "code",
      "source": [
        "# Checking the shape of the OHE array for the first digit position\n",
        "np.shape(train_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oe8PQKllIT2N"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Keras\n",
        "Reshape image data to be processed by Keras."
      ]
    },
    {
      "metadata": {
        "id": "WTQg2PaWLzc0"
      },
      "cell_type": "code",
      "source": [
        "def prep_data_keras(img_data):\n",
        "\n",
        "    # Reshaping data for keras, with tensorflow as backend\n",
        "    img_data = img_data.reshape(len(img_data), 64, 64, 1)\n",
        "\n",
        "    # Converting everything to floats\n",
        "    img_data = img_data.astype('float32')\n",
        "\n",
        "    # Normalizing values between 0 and 1\n",
        "    img_data /= 255\n",
        "\n",
        "    return img_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHUhGAErL--5"
      },
      "cell_type": "code",
      "source": [
        "train_images = prep_data_keras(train_dataset)\n",
        "test_images = prep_data_keras(test_dataset)\n",
        "valid_images = prep_data_keras(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D2p7Py9wMBGw"
      },
      "cell_type": "code",
      "source": [
        "np.shape(train_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tyXraB2MMQvR"
      },
      "cell_type": "code",
      "source": [
        "np.shape(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INF-j_J_MTi_"
      },
      "cell_type": "code",
      "source": [
        "# Importing relevant keras modules\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adadelta, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sj66iuNtLfJu"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "Build Deep Learning model to process data."
      ]
    },
    {
      "metadata": {
        "id": "ixTneFcAM_BN"
      },
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "batch_size = 32\n",
        "nb_classes = 11\n",
        "nb_epoch = 24\n",
        "\n",
        "# image input dimensions\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "img_channels = 1\n",
        "\n",
        "# number of convulation filters to use\n",
        "nb_filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (2, 2)\n",
        "# convolution kernel size\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "# defining the input\n",
        "inputs = Input(shape=(img_rows, img_cols, img_channels))\n",
        "\n",
        "# Model taken from keras example.\n",
        "cov = Conv2D(nb_filters,kernel_size=(kernel_size[0],kernel_size[1]),padding='same', use_bias=False)(inputs)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D(nb_filters,kernel_size=(kernel_size[0],kernel_size[1]),padding='same', use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.3)(cov)\n",
        "\n",
        "cov = Conv2D((nb_filters * 2),kernel_size=(kernel_size[0],kernel_size[1]), use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D((nb_filters * 2),kernel_size=(kernel_size[0],kernel_size[1]),padding='same', use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.3)(cov)\n",
        "\n",
        "\n",
        "cov = Conv2D((nb_filters * 4),kernel_size=(kernel_size[0],kernel_size[1]), use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D((nb_filters * 4),kernel_size=(kernel_size[0],kernel_size[1]),padding='same', use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.3)(cov)\n",
        "\n",
        "cov = Conv2D((nb_filters * 8),kernel_size=(kernel_size[0],kernel_size[1]), use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D((nb_filters * 8),kernel_size=(kernel_size[0],kernel_size[1]),padding='same', use_bias=False)(cov)\n",
        "cov = BatchNormalization()(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.3)(cov)\n",
        "\n",
        "cov_out = Flatten()(cov)\n",
        "\n",
        "\n",
        "# Dense Layers\n",
        "cov2 = Dense(2056, activation='relu')(cov_out)\n",
        "cov2 = Dropout(0.3)(cov2)\n",
        "\n",
        "\n",
        "\n",
        "# Prediction layers\n",
        "c0 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c1 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c2 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c3 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c4 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "\n",
        "# Defining the model\n",
        "model = Model(inputs=inputs,outputs=[c0,c1,c2,c3,c4])\n",
        "print (model.summary())\n",
        "\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(train_images,train_labels,batch_size=batch_size,epochs=nb_epoch,verbose=1,\n",
        "          validation_data=(valid_images, valid_labels), callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1gl0EeoPo6k"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijyU9tJ3Psbr"
      },
      "cell_type": "code",
      "source": [
        "np.shape(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZ9WBF1yQRG3"
      },
      "cell_type": "code",
      "source": [
        "len(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYoCA76RQWRm"
      },
      "cell_type": "code",
      "source": [
        "np.shape(test_labels)\n",
        "print(predictions[0][0])\n",
        "print(np.argmax(predictions[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8gkvmbWLoY1"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate Accuracy\n",
        "Custom accuracy calculation for individual digits and the whole sequence."
      ]
    },
    {
      "metadata": {
        "id": "UHb7NM2sQZ3U"
      },
      "cell_type": "code",
      "source": [
        "def calculate_acc(predictions,real_labels):\n",
        "\n",
        "    individual_counter = 0\n",
        "    global_sequence_counter = 0\n",
        "    coverage_counter = 0\n",
        "    confidence = 0.7\n",
        "    for i in range(0,len(predictions[0])):\n",
        "        # Reset sequence counter at the start of each image\n",
        "        sequence_counter = 0\n",
        "\n",
        "        for j in range(0,5):\n",
        "\n",
        "            if np.argmax(predictions[j][i]) == np.argmax(real_labels[j][i]):\n",
        "                individual_counter += 1\n",
        "                sequence_counter += 1\n",
        "            if predictions[j][i][np.argmax(predictions[j][i])] >= confidence:\n",
        "                coverage_counter += 1\n",
        "\n",
        "        if sequence_counter == 5:\n",
        "            global_sequence_counter += 1\n",
        "\n",
        "    ind_accuracy = individual_counter / float(len(predictions[0]) * 5)\n",
        "    global_accuracy = global_sequence_counter / float(len(predictions[0]))\n",
        "    coverage = coverage_counter / float(len(predictions[0]) * 5)\n",
        "\n",
        "    return ind_accuracy,global_accuracy, coverage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZSUiAerQ7tq"
      },
      "cell_type": "code",
      "source": [
        "ind_acc, glob_acc, coverage = calculate_acc(predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_I57NhTmRu2P"
      },
      "cell_type": "code",
      "source": [
        "print(\"The individual accuracy is {} %\".format(ind_acc * 100))\n",
        "print(\"The sequence prediction accuracy is {} %\".format(glob_acc * 100))\n",
        "print(\"The coverage is {} %\".format(coverage * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TI7q72qiR49W"
      },
      "cell_type": "code",
      "source": [
        "# Printing some examples of real and predicted labels\n",
        "for i in random.sample(range(0,10000),5):\n",
        "\n",
        "    actual_labels = []\n",
        "    predicted_labels = []\n",
        "    plt.figure()\n",
        "    plt.imshow(test_dataset[i])\n",
        "    for j in range(0,5):\n",
        "        actual_labels.append(np.argmax(test_labels[j][i]))\n",
        "        predicted_labels.append(np.argmax(predictions[j][i]))\n",
        "\n",
        "    print(\"Actual labels: {}\".format(actual_labels))\n",
        "    print(\"Predicted labels: {}\\n\".format(predicted_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BAwhIZqSZG8"
      },
      "cell_type": "markdown",
      "source": [
        "Source: https://sajalsharma.com/portfolio/digit_sequence_recognition"
      ]
    },
    {
      "metadata": {
        "id": "doUkPKQI-uQg"
      },
      "cell_type": "markdown",
      "source": [
        "## Export model"
      ]
    },
    {
      "metadata": {
        "id": "2x6kp7S7-zJM"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework import graph_util\n",
        "from tensorflow.python.framework import graph_io\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import os.path as osp\n",
        "from os import mkdir\n",
        "from google.colab import files\n",
        "\n",
        "prefix_output_node_names_of_final_network = 'output_node'\n",
        "\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "pred = [None]*5\n",
        "pred_node_names = [None]*5\n",
        "for i in range(0, 5):\n",
        "    pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)\n",
        "    pred[i] = tf.identity(model.output[i], name=pred_node_names[i])\n",
        "print('output nodes names are: ', pred_node_names)\n",
        "\n",
        "sess = K.get_session()\n",
        "output_fld = 'tensorflow_model/'\n",
        "if not osp.isdir(output_fld):\n",
        "    mkdir(output_fld)\n",
        "output_graph_name = 'svhn_model' + '.pb'\n",
        "output_graph_suffix = '_inference'\n",
        "\n",
        "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
        "graph_io.write_graph(constant_graph, output_fld, output_graph_name, as_text=False)\n",
        "print('saved the constant graph (ready for inference) at: ', osp.join(output_fld, output_graph_name))\n",
        "files.download(osp.join(output_fld, output_graph_name))  # from colab to browser download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZuxyt_JGqsA"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload file and Explore\n",
        "Adds ability to upload images to Google Colab for predicting images manually."
      ]
    },
    {
      "metadata": {
        "id": "YbIkl_TNU4hx"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R79TgLqucYM6"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "img = cv2.imread('5.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray = cv2.resize(img_gray, (64, 64))\n",
        "arr = img_gray[np.newaxis, :, :]\n",
        "arr = prep_data_keras(arr)\n",
        "prediction = model.predict(arr)\n",
        "for i in range(0, 5):\n",
        "  print(np.argmax(prediction[i][0]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WVofCYVuhXny"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "img = cv2.imread('6.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray = cv2.resize(img_gray, (64, 64))\n",
        "arr = img_gray[np.newaxis, :, :]\n",
        "arr = prep_data_keras(arr)\n",
        "prediction = model.predict(arr)\n",
        "for i in range(0, 5):\n",
        "  print(np.argmax(prediction[i][0]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0TzoAd5fgDq"
      },
      "cell_type": "code",
      "source": [
        "img = cv2.imread('50.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray = cv2.resize(img_gray, (64, 64))\n",
        "arr = img_gray[np.newaxis, :, :]\n",
        "arr = prep_data_keras(arr)\n",
        "prediction = model.predict(arr)\n",
        "for i in range(0, 5):\n",
        "  print(np.argmax(prediction[i][0]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F51qYwPwfvSH"
      },
      "cell_type": "code",
      "source": [
        "img = cv2.imread('31.png')\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_gray = cv2.resize(img_gray, (64, 64))\n",
        "arr = img_gray[np.newaxis, :, :]\n",
        "arr = prep_data_keras(arr)\n",
        "prediction = model.predict(arr)\n",
        "for i in range(0, 5):\n",
        "  print(np.argmax(prediction[i][0]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFRpjyTAXb4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}